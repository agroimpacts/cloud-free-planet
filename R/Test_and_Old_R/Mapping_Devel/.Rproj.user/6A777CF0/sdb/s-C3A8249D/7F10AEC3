{
    "contents" : "#! /usr/bin/R -f\n##############################################################################################################\n# Title      : KMLAccuracyCheck_1.2.3.R\n# Purpose    : Development of QAQC accuracy assessment side of Google Earth/Maps Africa field mapping project\n# Author     : Lyndon Estes\n# Draws from : GMap.grid.R, GMap.server.[1|1.1].R; GMap.acc.check.1.R; GMap.QAQC.check.1.1.R\n#              KMLAccuracyCheck_1.X.R\n# Used by    : \n# Notes      : Created 19/11/2012 (version 1.2.1)\n#              Note on the True Skill Statistic: This has been replaced by the overall accuracy score from \n#              Version *1.2.X.R onwards because it is more forgiving and gives more credit for TRUE negative\n#              errors. \n#              Changes: \n#                 * Installed numerous testing switches and routines (retrieve assignment id, test from \n#                   mac off-server, write accuracy measures to text file, map error components)\n#                 * Projected coordinate system now read in EPSG id from ***REMOVED*** database\n#                 * Counting user fields as error component\n#                 * Mapping accuracy in grid box now assessed with overall accuracy, but switch allows TSS\n#                   to be used \n#                 * Checking input polygons (qaqc and user) for overlaps, and unioning any that are found\n#                 * Reduced code lines by moving up polygon read in functions to beginning of section \n#                   codes. Introduced polygons cleaning function here, and created two new variables to \n#                   record number of rows in user and qaqc fields before unioning (user_nfields, qaqc_nfields)\n#                     ** Changed countError function to take vectors rather than spatial objects to deal with\n#                        this change\n#                  20/11/12:\n#                  * Fixed missing user_nfields in err.out vectors for Cases 2-4\n#                  * Removed line feeds in cat commands, suppressed dev.off() messages\n#                  28/11/12: Version update to 1.2.2. Changes tested in 1.2.1.test.R in /Test_and_Old_R \n#                    to prevent conflict with active use of system\n#                    Fixes:\n#                    * Fixed bug throwing null results in mapError: set null tp,fp,fn,tn values to 0 before \n#                      passing to function calling gArea: fixes lines 155-156\n#                    * Fixed incorrect accuracy statistic as found with assignment id \n#                      286PLSP75KLMCLHI0Z8QHQVJRSKZTB. Result too generous. Fix by making sure correct names\n#                      are being referenced in call to accStatsSum. Lines 157-178\n#                    Additions:\n#                    * Added time stamp to output plots so that multiple results of assignment can be kept\n#                      Lines 386-388\n#                    * Added statements to pass error components to error_data table: Lines 346-349\n#                    * Conditional statements put into lines 94-109 to allow testing with either kmlid or \n#                      assignmentid entered singly\n#                  29/11/12: \n#                    Fixes\n#                    * Intersection bug caused in case 3 with fields intersection issues. Updated all by \n#                      setting all gIntersection and gDifference operations to byid = T\n#                    * Plotting option did not draw portion of QAQC outside of grid. Added qaqc.poly.out\n#                      routine to case use (line 306)\n#                    * After first fix, still found error caused in case 4 with geometries being contained by\n#                      other geometries at qaqc.poly.out call under case 4. Fixed by turning off function\n#                      cleanPolyByUnion and replacing with straight gUnaryUnion function. Seems to work\n#                    * Error thrown by null tpo/tno error under case 4 where both user and qaqc fields outside\n#                      of grid didn't intersect: transported in same fix from mapError function\n#                    * Bug for plotting function caused by null tpo/fno results also fixed by adding check for\n#                      is.object to conditional statement\n#                    Additions\n#                    * Added conditional statement and switch to toggle writing to error_data on and off\n#                  5/4/2013: \n#                    Beginning point for code version update to KMLAccuracyCheck.1.2.3.R\n#                    Fixes: \n#                    * Major modification: Polygon cleaning installed via pprepair to fix unclean topologies\n#                      This means that user and qaqc polygons are read in, polygon numbers counted, written to\n#                      temporary ESRI shapefiles, cleaned via pprepair to new temporary shapefiles, then read\n#                      back in for error checking operations. This is achieved via two new functions: \n#                      ** callPprepair, which is used by createCleanTempPolyfromWKT\n#                      ** These replace cleanPolyByUnions and createPolyfromWKT\n#                    * gUnaryUnion is still performed on the cleaned polygon sets to facilitate easier merges\n#                      and intersects\n#                   19/4/2013: \n#                     Note: Bug remains in pprepair on one set of polygons that starts an infinite loop\n#                    \n##############################################################################################################\n# Hardcoded values placed here for easy changing \nprjsrid       <- 97490  # EPSG identifier for equal area project\ncount.err.wt  <- 0.1  # Weighting given to error in number of fields identified \nin.err.wt     <- 0.7  # Weighting for in grid map discrepancy\nout.err.wt    <- 0.2  # Weighting for out of grid map discrepancy\nerr.switch    <- 1  # Selects which area error metric used for in grid accuracy: 1 = overall accuracy; 2 = TSS\ncomments      <- \"F\"  # For testing, one can turn on print statements to see what is happening\nconsel        <- \"africa\"  # postgres connection switch: \"africa\" when run on server, \"mac\" for off server\nwrite.err.log <- \"T\"  # Option to write text log containing error metrics (anything besides \"T\" turns off)\nwrite.err.db  <- \"T\"  # Option to write error metrics into error_data table in postgres (off if not \"T\") \ndraw.maps     <- \"T\"  # Option to draw maps showing output error components (where maps possible, off w/o \"T\")\ntest          <- \"F\"  # For manual testing, one can give a single kmlid, and the code will pull the entire \n                      # assignment_data and hit_data tables to find the right assignment ids to test, \"Y\" for \n                      # this option, else \"N\" for normal production runs\n##############################################################################################################\n\n# Libraries\nsuppressMessages(library(RPostgreSQL))\nsuppressMessages(library(rgdal))\nsuppressMessages(library(rgeos))\n#suppressMessages(library(maptools))\n\n# Paths and connections\ndrv <- dbDriver(\"PostgreSQL\")\nif(consel == \"africa\") {\n  con <- dbConnect(drv, dbname = \"SouthAfrica\", user = \"***REMOVED***\", password = \"***REMOVED***\")\n} \nif(consel == \"mac\") {\n  con <- dbConnect(drv, host = \"africa.princeton.edu\", port = 5432, dbname = \"SouthAfrica\", user = \"***REMOVED***\", \n                   password = \"***REMOVED***\")\n}\n  \n# Input args\nif(test == \"N\") {\n  args <- commandArgs(TRUE)\n  kmlid <- args[1]  # ID of grid cell \n  assignmentid <- args[2]  # Job identifier\n  if(comments == \"T\") print(kmlid)\n  if(comments == \"T\") print(assignmentid)\n}\n\n#########################\n# Testing variables for remote off Africa access\nif(test == \"Y\") {\n  hit.sql <- \"select hit_id, name from hit_data\"\n  hits <- dbGetQuery(con, hit.sql)\n  ass.sql <- \"select assignment_id, hit_id, worker_id, score from assignment_data\"\n  asses <- dbGetQuery(con, ass.sql)\n  #userall.sql <- \"select name, assignment_id, ST_AsEWKT(geom) from user_maps order by name\"\n  #userallmaps <- dbGetQuery(con, userall.sql)\n\n  # If you have the kmlid \n  if(exists(\"kmlid\") & !exists(\"assignmentid\")) {\n    print(\"Using HIT ID to find assignment ID\")\n    hid <- hits[hits$name == kmlid, \"hit_id\"]\n    assignmentid <- asses[asses$hit_id == hid, \"assignment_id\"]\n    if(length(assignmentid) > 1) { \n      print(\"More than one assignment has been completed for this kml, selecting the first 1\")\n      assignmentid <- assignmentid[1]\n    }\n  }\n  # If you have the assigment id\n  if(exists(\"assignmentid\") & !exists(\"kmlid\")) {\n    print(\"Using assignment ID to find HIT ID\")\n    hid <- asses[asses$assignment_id == assignmentid, \"hit_id\"]\n    kmlid <- hits[hits$hit_id == hid, \"name\"]\n  }\n}\n########################\n\n# Projections \nprj.sql <- paste(\"select proj4text from spatial_ref_sys where srid=\", prjsrid, sep = \"\")\nprjstr <- dbGetQuery(con, prj.sql)$proj4text\ngcs <- \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"  # Always this one\n\n##############################################################################################################\n# Functions: \naccStatsSum <- function(tp, fp, tn, fn) {\n  # Calculate error statistics for two class contingency table\n  agree <- tp / sum(tp, fn)  # Simple agreement class 1\n  if(is.na(agree)) agree <- 0  # Set to 0 if NA\n  accuracy <- sum(tp, tn) / sum(tp, tn, fp, fn)\n  TSS <- agree + (tn / (fp + tn)) - 1  # Sens + specificity - 1\n  #r1 <- round(accuracy * 100, 1)\n  r1 <- round(accuracy, 2)\n  r2 <- round(TSS, 2)\n  out <- c(r1, r2)\n  names(out) <- c(\"accuracy\", \"TSS\")          \n  return(out)\n}\n\nmapError <- function(maps, truth, region) {\n# Calculates mapping accuracy for polygons relative to a \"true\" set of polygons\n# Args: \n#   maps: The input polygons to check - can be null in case where QAQC fields exist but user maps none\n#   truth: The polygons against which which accuracy will be assessed - can be NULL in case where user maps\n#     exist but \"truth\" maps do not\n#   region: A polygon defining the region in which accuracy is assessed\n \n  if(is.null(truth)) {\n    null <- region  # Actual null area is whole region\n    tp <- 0  # True positive area is 0\n    fp <- maps  # False positive area is all of maps\n    fn <- 0  # No false negative area because there are no fields\n    tn <- gDifference(spgeom1 = null, spgeom2 = maps, byid = F)  # false negative area (maps no, truth yes)\n  } \n  if(is.null(maps)) {\n    null <- gDifference(spgeom1 = region, spgeom2 = truth, byid = F)  # Actual null area in mapping region \n    tp <- 0  # No user maps, no true positive\n    fp <- 0  # No user maps, no false positives\n    fn <- truth  # False negative area is all of truth\n    tn <- null  # True negative area is null - user gets credit for this area, even if missed fields\n  }\n  if(!is.null(truth) & !is.null(maps)) {\n    null <- gDifference(spgeom1 = region, spgeom2 = truth, byid = T)  # Actual null area in mapping region \n    tp <- gIntersection(spgeom1 = truth, spgeom2 = maps, byid = T)  # true positives (overlap of maps & truth)\n    fp <- gDifference(spgeom1 = maps, spgeom2 = truth, byid = T)  # false positive area (maps yes, truth no)\n    fn <- gDifference(spgeom1 = truth, spgeom2 = maps, byid = T)  # false negative area (maps no, truth yes)\n    tn <- gDifference(spgeom1 = null, spgeom2 = maps, byid = T)  # false negative area (maps no, truth yes)\n  }\n  tflist <- c(\"tp\", \"fp\", \"fn\", \"tn\")  # 28/11/12: Bug fix for crash in areas caused by null fp results\n  areas <- sapply(tflist, function(x) ifelse(!is.null(get(x)) & is.object(get(x)), gArea(get(x)), 0))\n  names(areas) <- tflist  # Added 28/11/12 to have specific names from areas to pass to accStatsSum\n  #areas <- sapply(list(tp, fp, tn, fn), function(x) ifelse(is.object(x), gArea(x), x))\n  # 28/11/12: Specific names referenced in call to accStatsSum\n  list(accStatsSum(tp = areas[\"tp\"], fp = areas[\"fp\"], fn = areas[\"fn\"], tn = areas[\"tn\"]), tp, fp, fn, tn)  \n}\n\n# createSPPolyfromWKT <- function(geom.tab, crs) {\n# # Function for reading in and creating SpatialPolygonsDataFrame from PostGIS\n# # Args: \n# #   geom.tab: Dataframe with geometry and identifiers in it. Identifier must be 1st column, geometries 2nd col  \n# #   crs: Coordinate reference system\n# # Returns: \n# #   A SpatialPolygonsDataFrame\n#   polys <- tst <- sapply(1:nrow(geom.tab), function(x) {\n#     poly <- as(readWKT(geom.tab[x, 2], p4s = crs), \"SpatialPolygonsDataFrame\")\n#     poly@data$ID <- geom.tab[x, 1]\n#     newid <- paste(x)\n#     poly <- spChFIDs(poly, newid)\n#     return(poly)\n#   })\n#   polyspdf <- do.call(\"rbind\", polys)\n# }\n\ncountError <- function(qaqc_rows, user_rows) {\n# Calculates percent agreement between number of fields in qaqc and user kmls\n# Args: \n#  qaqc_rows: vector containing number of QAQC rows, or NULL if one doesn't exist\n#  kml: User mapped fields, or NULL if they don't exist\n# Returns: Score between 0-1\n# Notes: Rearranges numerator and denominator of equation according to whether user mapped fields are more \n# or less than QAQC fields\n  #qaqc.row <- ifelse(is.null(qaqc), 0, nrow(qaqc))\n  #kml.row <- ifelse(is.null(kml), 0, nrow(kml))\n  cden <- ifelse(qaqc_rows >= user_rows, qaqc_rows, user_rows)\n  cnu1 <- ifelse(qaqc_rows >= user_rows, qaqc_rows, user_rows)\n  cnu2 <- ifelse(qaqc_rows >= user_rows, user_rows, qaqc_rows)\n  cnterr <- 1 - (cnu1 - cnu2) / cden  # Percent agreement\n  return(cnterr)\n}\n\n# cleanPolybyUnion <- function(poly.in) {\n# # To prevent rgeos errors caused by overlapping polygons, this function checks input polygons for overlaps \n# # and performs a gUnaryUnion on any overlapping polygons\n# # Args: \n# #  poly.in:  Input polygons\n# # Returns: \n# #  Polygons with overlaps returned, if any\n# \n#   o <- gOverlaps(poly.in, byid = T)\n#   if(any(o)) {\n#     poly.out <- gUnaryUnion(poly.in) \n#   } else {\n#     poly.out <- poly.in\n#   }\n#   return(poly.out)\n# }\n\n# removeOverlaps <- function(x) {\n#   #newpoly <- SpatialPolygons(lapply(1:length(x), function(z) Polygons(x@polygons[[1]]@Polygons, z)))\n#   outpoly <- x\n#   newpoly2 <- lapply(1:length(outpoly), function(j) outpoly[j, ])\n#   itab <- gOverlaps(outpoly, byid = T)\n#   itab[which(itab)] <- 1\n#   itab1 <- rowSums(itab)\n#   i <- which(itab1 > 0)[1]\n# \n#   while(i <= length(outpoly)) {\n#     a <- outpoly[i, ]\n#     b <- outpoly[-i, ]\n#     d <- b[which(gOverlaps(a, b, byid = T)), ]\n#     plot(newpoly2[[i]], add = T, col = \"green\")\n#     plot(b)\n#     plot(e, add = T, border = \"maroon\")\n#     plot(d, add = T, col = \"red\")\n#     plot(a, add = T, border = \"green\")\n#     d <- gUnaryUnion(d)\n#     plot(gDifference(outpoly, outpoly2, byid = T))\n#     newpoly2[[i]] <- gDifference(spgeom1 = a, spgeom2 = d, byid = T)\n#     outpoly2 <- SpatialPolygons(lapply(1:length(newpoly2), function(j) {\n#       Polygons(newpoly2[[j]]@polygons[[1]]@Polygons, j)\n#     }))\n#     itab <- gOverlaps(outpoly, byid = T)\n#     itab[which(itab)] <- 1\n#     itab1 <- rowSums(itab)\n#     ct <- which(itab1 > 0)[1]\n#     i <- unname(ifelse(is.na(ct), length(outpoly) + 1, ct)) \n#     print(i)\n#   } \n# }  # Commented out 4/4/13\n\n# Swtiching off grass cleaning 4/4/13\n# library(spgrass6)\n# SG <- Sobj_SpatialGrid(qaqc.poly)$SG\n# loc <- initGRASS(\"/Applications/GRASS-6.4.app/Contents/MacOS/\", home=tempdir(), SG, override = TRUE)\n# tf <- tempfile()\n# mapset <- execGRASS(\"g.gisenv\", parameters=list(get=\"MAPSET\"), intern=TRUE)\n# execGRASS(\"g.gisenv\", parameters=list(set=shQuote('MAPSET=PERMANENT')))\n# prj <- showWKT(proj4string(qaqc.poly), tf)\n# execGRASS(\"g.proj\", flags=\"c\", parameters=list(wkt=tf))\n# execGRASS(\"g.proj\", flags=\"p\")\n# execGRASS(\"g.gisenv\", parameters=list(set=paste(\"'MAPSET=\", mapset, \"'\", sep=\"\")))\n# execGRASS(\"g.region\", flags=\"d\")\n# writeVECT6(qaqc.poly, \"qaqc\")\n# o <- readVECT6(\"qaqc\", with_c=FALSE, remove.duplicates = F)\n# polylist <- lapply(1:length(unique(o@data$cat)), function(x) gUnaryUnion(o[o@data$cat == x, ]))\n# newpoly <- SpatialPolygons(lapply(1:length(unique(o@data$cat)), function(x) {\n#   Polygons(polylist[[x]]@polygons[[1]]@Polygons, x)\n# }))\n# \n# outpoly <- newpoly\n# newpoly2 <- lapply(1:length(newpoly), function(j) newpoLy[j, ])\n# itab <- gOverlaps(outpoly, byid = T)\n# itab[which(itab)] <- 1\n# itab1 <- rowSums(itab)\n# i <- which(itab1 > 0)[1]\n# \n# while(i <= length(newploy)) {\n#   a <- outpoly[i, ]\n#   b <- outpoly[-i, ]\n#   d <- b[which(gOverlaps(a, b, byid = T)), ]\n#   d <- gUnaryUnion(d)\n#   newpoly2[[i]] <- gDifference(spgeom1 = a, spgeom2 = gUnaryUnion(d), byid = T)\n#   outpoly <- SpatialPolygons(lapply(1:length(newpoly2), function(x) {\n#     Polygons(newpoly2[[x]]@polygons[[1]]@Polygons, x)\n#   }))\n#   itab <- gOverlaps(outpoly, byid = T)\n#   itab[which(itab)] <- 1\n#   itab1 <- rowSums(itab)\n#   ct <- which(itab1 > 0)[1]\n#   i <- unname(ifelse(is.na(ct), length(newploy) + 1, ct)) \n#   print(i)\n# }  \n# plot(outpoly)\n# gOverlaps(outpoly, byid = T)\n# plot(newpoly2[[i]])\n\ncallPprepair <- function(dirnm, spdfinname, spdfoutname, crs = crs) {\n# Function to make system call to polygon cleaning program pprepair\n# Args: \n#   dirnm: directory where the shapefiles will go\n#   spdfinname: Name of the ESRI shapefile written to disk that needs cleaning, without the .shp extension\n#   spdfoutname: Name of shapefile that pprepair should write to, without the .shp extension\n# Returns: \n#   spdf of cleaned polygons, pointing to a temporary shapefile written to disk\n  \n  #crs = prjstr\n  #dirnm = td; spdfinname = tmpnmin; spdfoutname = tmpnmout\n  inname <- paste(dirnm, \"/\", spdfinname, \".shp\", sep = \"\")\n  outname <- paste(dirnm, \"/\", spdfoutname, \".shp\", sep = \"\")\n  ppcall <- paste(\"/usr/local/bin/pprepair -i\", inname, \"-o\", outname, \"-fix\")\n  ctch <- system(ppcall, intern = TRUE)\n  polyfixed <- readOGR(dsn = dirnm, layer = spdfoutname, verbose = FALSE)\n  polyfixed@proj4string <- crs\n  return(polyfixed)\n}\n\ncreateCleanTempPolyfromWKT <- function(geom.tab, crs) {\n# Function for reading in a spatial geometry from PostGIS and creating a temporary shapefile out of it  \n# Args: \n#   geom.tab: Dataframe with geometry and identifiers in it. Identifier must be 1st column, geometries 2nd col  \n#   crs: Coordinate reference system\n# Returns: \n#   A SpatialPolygonsDataFrame\n# Notes: \n#   Uses callPprepair function to clean up read in polygons and write them to a temporary location\n  polys <- tst <- sapply(1:nrow(geom.tab), function(x) {\n    poly <- as(readWKT(geom.tab[x, 2], p4s = crs), \"SpatialPolygonsDataFrame\")\n    poly@data$ID <- geom.tab[x, 1]\n    newid <- paste(x)\n    poly <- spChFIDs(poly, newid)\n    return(poly)\n  })\n  polyspdf <- do.call(\"rbind\", polys)\n  polys.count <- nrow(polyspdf)\n  #td <- \"/var/www/html/afmap/R/tmp/\"\n  td <- tempdir()\n  tmpnmin <- strsplit(tempfile(\"poly\", tmpdir = \"\"), \"/\")[[1]][2]\n  tmpnmout <- strsplit(tempfile(\"poly\", tmpdir = \"\"), \"/\")[[1]][2]\n  writeOGR(polyspdf, dsn = td, layer = tmpnmin, driver = \"ESRI Shapefile\")\n  polyfixed <- callPprepair(td, spdfinname = tmpnmin, spdfoutname = tmpnmout, crs = polyspdf@proj4string)\n  valid.string <- as.character(gIsValid(polyfixed))\n  return(list(\"polygons\" = polyfixed, \"polygoncount\" = polys.count, \"validity\" = valid.string))\n}\n\n##############################################################################################################\n\n# First check if the QAQC site is null or not\nqaqc.sql <- paste(\"select fields from newqaqc_sites where name=\", \"'\", kmlid, \"'\", sep = \"\")\nqaqc.hasfields <- dbGetQuery(con, qaqc.sql)$fields  # Check fields column in master qaqcs sites database\nif(qaqc.hasfields == \"Y\") {\n  qaqc.fields.sql <- paste(\"select id,ST_AsEWKT(geom) from qaqcfields where name=\", \"'\", kmlid, \"'\", sep = \"\")\n  qaqc.geom.tab <- dbGetQuery(con, qaqc.fields.sql)\n  qaqc.geom.tab[, 2] <- gsub(\"^SRID=*.*;\", \"\", qaqc.geom.tab[, 2])\n  #qaqc.poly <- createSPPolyfromWKT(geom.tab = qaqc.geom.tab, crs = prjstr)\n  #qaqc.nfields <- nrow(qaqc.poly)  # Collect number of unique fields before cleaning\n  #qaqc.poly <- cleanPolybyUnion(qaqc.poly)  # Clean up any overlaps\n  #qaqc.poly <- gUnaryUnion(qaqc.poly)  # Clean up any overlaps\n  #qaqc.poly <- gUnaryUnion(gBuffer(qaqc.poly, byid = TRUE, width = 0)) # 30/11/12 Bug fix for self-int\n  qaqc.poly.list <- createCleanTempPolyfromWKT(geom.tab = qaqc.geom.tab, crs = prjstr)\n  qaqc.poly <- gUnaryUnion(qaqc.poly.list[[1]])\n  qaqc.nfields <- qaqc.poly.list[[2]]\n}\n\n# Read in user data\nuser.sql <- paste(\"select name,ST_AsEWKT(geom) from user_maps where assignment_id=\", \"'\", \n                 assignmentid, \"'\", \" order by name\", sep = \"\")\n# user.sql <- paste(\"select name,ST_AsEWKT(ST_MakeValid(geom)) from user_maps where assignment_id=\", \"'\", \n#                   assignmentid, \"'\", \" order by name\", sep = \"\")\nuser.geom.tab <- dbGetQuery(con, user.sql)  # Collect user data and fields geometries\nuser.hasfields <- ifelse(nrow(user.geom.tab) > 0, \"Y\", \"N\")  # Need to get this right\nif(user.hasfields == \"Y\") {  # Read in user fields if there are any\n  user.geom.tab[, 2] <- gsub(\"^SRID=*.*;\", \"\", user.geom.tab[, 2])\n  #user.poly.gcs <- createSPPolyfromWKT(geom.tab = user.geom.tab, crs = gcs)\n  user.poly.list <- createCleanTempPolyfromWKT(geom.tab = user.geom.tab, crs = gcs)\n  user.poly <- gUnaryUnion(spTransform(user.poly.list[[1]], CRSobj = CRS(prjstr)))  # Transform to Albers\n  user.nfields <- user.poly.list[[2]]  #  Record number of distinct fields observed by user\n  #user.poly <- cleanPolybyUnion(user.poly)  # Clean up any overlaps in user polygons\n  #user.poly <- gUnaryUnion(user.poly)  # Clean up any overlaps in user polygons\n  #user.poly <- gUnaryUnion(gBuffer(user.poly, byid = TRUE, width = 0))  # 30/11/12 Bug fix with self-int\n}\n\n# Error checks begin\n#  Where no QAQC site is recorded\n# Case 1: A null qaqc site recorded as null by the observer; score set to 1\nif((qaqc.hasfields == \"N\") & (user.hasfields == \"N\")) {\n  if(comments == \"T\") print(\"No QAQC or User fields\")\n  err <- 1  \n  err.out <- c(\"total_error\" = err, \"count_error\" = 1, \"out_error\" = 1, \"in_error\" = 1, \"user_fldcount\" = 0)\n} else {\n  # Pick up grid cell from qaqc table, for background location, as it will be needed for the other three cases\n  grid.sql <- paste(\"SELECT id,ST_AsEWKT(geom) from newqaqc_sites where name=\", \"'\", kmlid, \"'\", sep = \"\")\n  grid.geom.tab <- dbGetQuery(con, grid.sql)\n  grid.geom.tab[, 2] <- gsub(\"^SRID=*.*;\", \"\", grid.geom.tab[, 2])\n  #grid.poly <- createSPPolyfromWKT(geom.tab = grid.geom.tab, crs = prjstr)\n  grid.poly <- createCleanTempPolyfromWKT(geom.tab = grid.geom.tab, crs = prjstr)[[1]]\n}\n\n# Case 2: A null qaqc site with fields mapped by user\nif((qaqc.hasfields == \"N\") & (user.hasfields == \"Y\")) {\n  if(comments == \"T\") print(\"No QAQC fields, but there are User fields\") \n \n  # Accuracy measures\n  count.error <- 0  # Count accuracy is zero if QAQC has no fields but user maps even 1 field\n    \n  # Mapped area differences inside the target grid cell\n  user.poly.in <- gIntersection(spgeom1 = grid.poly, spgeom2 = user.poly, byid = T)  ### Turker maps in grid\n  inres <- mapError(maps = user.poly.in, truth = NULL, region = grid.poly)  # Main error metric - TSS\n  \n  # Secondary metric - Sensitivity of results outside of kml grid\n  user.poly.out <- gDifference(spgeom1 = user.poly, spgeom2 = grid.poly, byid = T)  ### Turker maps out \n  if(is.null(user.poly.out)) {  # 16/11/12: If user finds no fields outside of box, gets credit\n    out.error <- 1  \n  } else {  \n    out.error <- 0  # If user maps outside of box when no fields exist, sensitivity is 0\n  }\n\n  # Combine error metric\n  err <- count.error * count.err.wt + unname(inres[[1]][err.switch]) * in.err.wt + out.error * out.err.wt  \n  err.out <- c(\"total_error\" = err, \"count_error\" = count.error, \"out_error\" = out.error, \n               \"in_error\" = unname(inres[[1]][err.switch]), \"user_fldcount\" = user.nfields)\n}\n\n# Cases 3 & 4\nif(qaqc.hasfields == \"Y\") {\n  \n  #  Case 3. QAQC has fields, User has no fields\n  if(user.hasfields == \"N\") {\n    if(comments == \"T\") print(\"QAQC fields but no User fields\")\n    # Accuracy measures\n    count.error <- 0  # Count accuracy is zero if QAQC has fields but user maps none\n   \n    # Mapped area differences inside the target grid cell\n    qaqc.poly.in <- gIntersection(spgeom1 = grid.poly, spgeom2 = qaqc.poly, byid = T)  # QAQC inside grid cell\n    qaqc.poly.out <- gDifference(spgeom1 = qaqc.poly, spgeom2 = grid.poly, byid = T)  # QAQC outside grid cell\n    inres <- mapError(maps = NULL, truth = qaqc.poly.in, region = grid.poly)  # Main error metric - TSS\n   \n    # Secondary metric - Sensitivity of results outside of kml grid\n    out.error <- 0  # reduces to 0, because there is neither true positive nor false negative\n   \n    # Combine error metric\n    err <- count.error * count.err.wt + unname(inres[[1]][err.switch]) * in.err.wt + out.error * out.err.wt  \n    err.out <- c(\"total_error\" = err, \"count_error\" = count.error, \"out_error\" = out.error, \n                 \"in_error\" = unname(inres[[1]][err.switch]), \"user_fldcount\" = 0)\n  \n  # Case 4. QAQC has fields, User has fields\n  } else if(user.hasfields == \"Y\") {\n    if(comments == \"T\") print(\"QAQC fields and User fields\")\n   \n    # Accuracy measures\n    count.error <- countError(qaqc_rows = qaqc.nfields, user_rows = user.nfields)  # Count accuracy\n    \n    # Mapped area differences inside the target grid cell\n    user.poly.in <- gIntersection(spgeom1 = grid.poly, spgeom2 = user.poly, byid = T) # Turker maps in grid\n    #qaqc.poly.in <- gIntersection(spgeom1 = grid.poly, spgeom2 = gBuffer(qaqc.poly, byid = T, width = 0), byid = T) # QAQC inside grid cell\n    qaqc.poly.in <- gIntersection(spgeom1 = grid.poly, spgeom2 = qaqc.poly, byid = T) # QAQC inside grid cell\n    user.poly.out <- gDifference(spgeom1 = user.poly, spgeom2 = grid.poly, byid = T)  # Turker maps out \n    qaqc.poly.out <- gDifference(spgeom1 = qaqc.poly, spgeom2 = grid.poly, byid = T)  # QAQC outside grid cell\n    inres <- mapError(maps = user.poly.in, truth = qaqc.poly.in, region = grid.poly)  # Error metric - TSS\n    \n    # Secondary metric - Sensitivity of results outside of kml grid\n    if(is.null(user.poly.out) & is.null(qaqc.poly.out)) {\n      if(comments == \"T\") print(\"No QAQC or User fields outside of grid\")\n      out.error <- 1  \n    } else if(!is.null(user.poly.out) & !is.null(qaqc.poly.out)) {\n      if(comments == \"T\") print(\"Both QAQC and User fields outside of grid\")\n      tpo <- gIntersection(spgeom1 = qaqc.poly.out, spgeom2 = user.poly.out)  # true positives (overlap)\n      fno <- gDifference(spgeom1 = qaqc.poly.out, spgeom2 = user.poly.out)  # true positives (overlap)\n      tflisto <- c(\"tpo\", \"fno\")  # 29/11/12: Bug fix for crash in areas caused by null intersect\n      areaso <- sapply(tflisto, function(x) ifelse(!is.null(get(x)) & is.object(get(x)), gArea(get(x)), 0))\n      #areaso <- sapply(list(tpo, fno), function(x) gArea(x))\n      out.error <- areaso[1] / sum(areaso)\n    } else {\n      if(comments == \"T\") print(\"Either QAQC or User fields outside of grid, but not both\")\n      out.error <- 0\n    }\n    \n    # Combine error metric\n    err <- count.error * count.err.wt + unname(inres[[1]][err.switch]) * in.err.wt + out.error * out.err.wt  \n    err.out <- c(\"total_error\" = err, \"count_error\" = count.error, \"out_error\" = out.error, \n                 \"in_error\" = unname(inres[[1]][err.switch]), \"user_fldcount\" = user.nfields)\n  }\n} \n\n# Insert error component statistics into the database\nif(write.err.db == \"T\") {\n  error.sql <- paste(\"insert into error_data (assignment_id, score, error1, error2, error3, error4) values ('\", \n                     assignmentid, \"', \", paste(err.out, collapse = \", \"), \")\", sep = \"\")\n  ret <- dbSendQuery(con, error.sql)\n}\n\n# Note: I want to keep some of the additional error metrics, if possible.  I can write them from here into \n# the database, or pass them all out to python, and have the python code handle that.  \n# For now, I am just passing out the primary error metric, which I am setting to zero if is is negative\n#score <- ifelse(err.out[1] < 0, 0, err.out[1])\nif(comments == \"T\") {\n  cat(err.out)\n} else {\n  cat(err.out[1])\n}\n\n# Write error metrics to log file\nif(write.err.log == \"T\") {\n  prj.file.path <- dbGetQuery(con, \"select value from configuration where key = 'ProjectRoot'\")$value\n  err.fname <- paste(prj.file.path, \"/R/Error_records/error_metrics.Rout\", sep = \"\")\n  err.strng <- paste(kmlid, assignmentid, paste(round(err.out, 4), collapse = \"  \"), sep = \"   \")\n  if(file.exists(err.fname)) {\n    write(err.strng, file = err.fname, append = T) \n  } else {\n    write(err.strng, file = err.fname)\n  } \n}\n\n# Map results according to error class\nif(draw.maps == \"T\") {\n \n  if(exists(\"grid.poly\")) bbr1 <- bbox(grid.poly)\n  if(exists(\"qaqc.poly\")) bbr2 <- bbox(qaqc.poly)\n  if(exists(\"user.poly\")) bbr3 <- bbox(user.poly)\n\n  cx <- 1.5 \n  lbbrls <- ls(pattern = \"^bbr\")\n  if(length(lbbrls) > 0) {\n    xr <- range(sapply(1:length(lbbrls), function(x) get(lbbrls[x])[1, ]))\n    yr <- range(sapply(1:length(lbbrls), function(x) get(lbbrls[x])[2, ]))\n    vals <- rbind(xr, yr)\n    \n    if(exists(\"grid.poly\")) {\n      prj.file.path <- dbGetQuery(con, \"select value from configuration where key = 'ProjectRoot'\")$value\n      tm <- format(Sys.time(), \"%Y%m%d%H%M%OS2\")  # Added 28/11/12 to time stamp output plots\n      pngname <- paste(prj.file.path, \"/R/Error_records/\", kmlid, \"_\", assignmentid, \"_\", tm, \".png\", \n                       sep = \"\")\n      png(pngname, height = 700, width = 700, antialias = \"none\")\n      plot(grid.poly, xlim = vals[1, ], ylim = vals[2, ])\n      objchk <- sapply(2:5, function(x) is.object(inres[[x]]))\n      mpi <- names(err.out)\n      plotpos <- c(0.15, 0.4, 0.65, 0.90)\n      cols <- c(\"green4\", \"red4\", \"blue4\", \"grey30\")\n      for(i in 1:4) {\n        if(objchk[i] == \"TRUE\") plot(inres[[i + 1]], add = T, col = cols[i])\n        mtext(round(err.out[i], 3), side = 3, line = -1, adj = plotpos[i], cex = cx)\n        mtext(mpi[i], side = 3, line = 0.5, adj = plotpos[i], cex = cx)\n        if(exists(\"user.poly.out\")) {\n          if(!is.null(user.poly.out)) plot(user.poly.out, add = T, col = \"grey\")\n        }\n        if(exists(\"qaqc.poly.out\")) {\n          if(!is.null(qaqc.poly.out)) plot(qaqc.poly.out, add = T, col = \"pink\")\n        }\n        if(exists(\"tpo\")) if(is.object(tpo)) plot(tpo, col = \"green1\", add = T)  # 29/11 added fix for nulls\n        if(exists(\"fno\")) if(is.object(tpo)) plot(fno, col = \"blue1\", add = T)   # 29/11 added fix for nulls\n      }\n      mtext(paste(kmlid, \"_\", assignmentid, sep = \"\"), side = 1, cex = cx)\n      legend(x = \"right\", legend = c(\"TP\", \"FP\", \"FN\", \"TN\"), pch = 15, bty = \"n\", col = cols, pt.cex = 3, \n             cex = cx)\n      garbage <- dev.off()  # Suppress dev.off message\n    }  \n  }\n}\n\n# Clean up a bit (aids with running tests)\n#rmnames <- ls(pattern = \"qaqc|err|user|count\\\\.|tpo|fpo|grid\\\\.|bbr|ass|kmlid\")\nrmnames <- ls()\nuser.sql <- paste(\"select name,ST_AsEWKT(geom) from user_maps where assignment_id=\", \"'\", \n                  assignmentid, \"'\", \" order by name\", sep = \"\")\nuser.sql <- paste(\"select name,ST_AsEWKT(geom) from user_maps where assignment_id=\", \"'\", \n                  assignmentid, \"'\", \" order by name\", sep = \"\")\nrm(list = rmnames[!rmnames %in% c(\"tab\", \"con\")])  # remove but for var nms for test & con \n\n# Close connection to prevent too many from being open\ngarbage <- dbDisconnect(con)\n\n\n",
    "created" : 1365094823272.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "149|41|161|0|\n163|43|198|0|\n217|46|232|0|\n",
    "hash" : "584507168",
    "id" : "7F10AEC3",
    "lastKnownWriteTime" : 1366405308,
    "path" : "/var/local/as/afmap/R/KMLAccuracyCheck.1.2.3.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}