{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing planet imagery for median mosaic\n",
    "\n",
    "1. mask clouds\n",
    "2. assign nodata for partial overlap scenes within bounds of supercell\n",
    "3. median for each band and composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio import mask\n",
    "import rasterstats as rstats\n",
    "import skimage as ski\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "import json\n",
    "os.chdir('../')\n",
    "from filter_callable import cloud_shadow_stats\n",
    "sr_pattern = \"/home/rave/cloud-free-planet/notebooks/jan_april_2018_100ovp_50maxcloud/*SR*.tif\"\n",
    "img_paths = glob.glob(sr_pattern)\n",
    "udm_pattern = \"/home/rave/cloud-free-planet/notebooks/jan_april_2018_100ovp_50maxcloud/*udm*.tif\"\n",
    "udm_paths = glob.glob(udm_pattern)\n",
    "\n",
    "img_paths = sorted(img_paths)\n",
    "\n",
    "udm_paths = sorted(udm_paths)\n",
    "\n",
    "def filter_date(lst, month_int, month_digit1, month_digit2):\n",
    "    \"\"\"Takes a list of udms or images and returns filtered by month lists\n",
    "    example\n",
    "    imgs_may = filter_date(img_paths, '05', 12, 14)\n",
    "    udms_may = filter_date(udm_paths, '05', 12, 14)\"\"\"\n",
    "    return [i for i in lst if os.path.basename(i)[month_digit1:month_digit2] == month_int]\n",
    "\n",
    "\n",
    "def test_udm_mask(image_path, udm_path):\n",
    "    \"\"\"\n",
    "    Masks a planet image by it's udm\n",
    "    \"\"\"\n",
    "\n",
    "    img = rio.open(image_path)\n",
    "    img_meta = img.profile\n",
    "    img_array = np.array([img.read(1), img.read(2), img.read(3), img.read(4)])\n",
    "    mask = rio.open(udm_path).read(1)[..., :] == 0 # 0 is the value in the udm that corresponds to good data\n",
    "    masked = np.where(mask,img_array, 0)\n",
    "    return np.swapaxes(np.swapaxes(masked, 0, 2),0, 1)\n",
    "\n",
    "\n",
    "def test_custom_mask(image_path):\n",
    "    \"\"\"\n",
    "    Masks a custom cloud mask from filter_callable\n",
    "    \"\"\"\n",
    "\n",
    "    img = rio.open(image_path)\n",
    "    img_meta = img.profile\n",
    "    cloud_arr, shadow_arr = cloud_shadow_stats(image_path)\n",
    "    cloud_arr = np.logical_not(cloud_arr.astype(bool))\n",
    "    shadow_arr = np.logical_not(shadow_arr.astype(bool))\n",
    "    masked = np.where(cloud_arr,img.read(), False)\n",
    "    masked = np.where(shadow_arr,masked, False)\n",
    "    return np.swapaxes(np.swapaxes(masked, 0, 2),0, 1)\n",
    "\n",
    "from skimage import exposure\n",
    "\n",
    "def percentile_rescale(arr, plow=1, phigh=99):\n",
    "    '''\n",
    "    Rescales and applies other exposure functions to improve image vis. \n",
    "    http://scikit-image.org/docs/dev/api/skimage.exposure.html#skimage.exposure.rescale_intensity\n",
    "    '''\n",
    "    rescaled_arr = np.zeros_like(arr)\n",
    "    for i in range(0,arr.shape[-1]):\n",
    "        val_range = (np.percentile(arr[:,:,i], plow), np.percentile(arr[:,:,i], phigh))\n",
    "        rescaled_channel = exposure.rescale_intensity(arr[:,:,i], val_range)\n",
    "        rescaled_arr[:,:,i] = rescaled_channel\n",
    "#     rescaled_arr= exposure.adjust_gamma(rescaled_arr, gamma=1) #adjust from 1 either way\n",
    "#     rescaled_arr= exposure.adjust_sigmoid(rescaled_arr, cutoff=.50) #adjust from .5 either way \n",
    "    return rescaled_arr\n",
    "def normalize(arr):\n",
    "    ''' Function to normalize an input array to 0-1 '''\n",
    "    arr_max = arr.max()\n",
    "    return arr / arr_max\n",
    "\n",
    "def reorder_to_rgb(image):\n",
    "    '''reorders wv2 bands ordered like RGBNRGN for off/onseason\n",
    "    to blue, red, green for imshow\n",
    "    '''\n",
    "    blue = normalize(image[:,:,2])\n",
    "    green = normalize(image[:,:,1])\n",
    "    red = normalize(image[:,:,0])\n",
    "    nir = normalize(image[:,:,3])\n",
    "    return np.stack([red, green, blue], axis=-1) \n",
    "\n",
    "def is_even(x):\n",
    "    if x%2 == 1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "def is_div_by(x, y):\n",
    "    if x%y == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def even_only(iter):\n",
    "    return [x for x in iter if is_even(x)]\n",
    "def odds_only(iter):\n",
    "    return [x for x in iter if not is_even(x)]\n",
    "def by_3_only(iter):\n",
    "    return [x for x in iter if is_div_by(x, 3)]\n",
    "def by_3_no_odd_only(iter):\n",
    "    return [x for x in iter if is_div_by(x, 3) and is_even(x)]\n",
    "def even_no_3_only(iter):\n",
    "    return [x for x in iter if not is_div_by(x, 3) and is_even(x)]\n",
    "def odd_no_3_only(iter):\n",
    "    return [x for x in iter if not is_div_by(x, 3) and not is_even(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_pattern = \"/home/rave/cloud-free-planet/notebooks/jan-may/*metadata.json\"\n",
    "meta_paths = glob.glob(meta_pattern)\n",
    "meta_paths = sorted(meta_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below functions are for ATSA\n",
    "\n",
    "need to turn the tifs into ENVI standard files like the example and stack the time series. Either stack in envi or stack as tifs before bringing to envi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_paths_with_meta = keep_imgs_with_meta(img_paths,meta_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sun_elevation_azimuth(path):\n",
    "    with open(path) as f:\n",
    "        metadata = json.load(f)\n",
    "    return (metadata['properties']['sun_elevation'], metadata['properties']['sun_azimuth'])\n",
    "\n",
    "angles = list(map(get_sun_elevation_azimuth, meta_paths))\n",
    "with open('angles.txt', 'w') as f:\n",
    "    for tup in angles:\n",
    "        f.write('%s %s\\n' % tup)\n",
    "\n",
    "def save_blank_water_mask(path):\n",
    "    \"\"\"Used for testing ATSA where we know ther eis no water\n",
    "    In the future we can use MOD44W water mask product or something else\n",
    "    \"\"\"\n",
    "    test = rio.open(path)\n",
    "    meta = test.profile\n",
    "    meta.update(count=1) # update since we are writing a single band\n",
    "    b1_array, b2_array, b3_array, b4_array = test.read()\n",
    "    fake_mask = np.zeros(b1_array.shape)\n",
    "    with rio.open('fake_mask.tif', 'w', **meta) as dst:\n",
    "        dst.write(fake_mask.astype('uint16'), 1)\n",
    "        \n",
    "save_blank_water_mask(img_paths_with_meta[0])\n",
    "\n",
    "with rio.open(img_paths_with_meta[0]) as test:\n",
    "    print(test.read().shape)\n",
    "\n",
    "def stack_t_series(paths, stackname):\n",
    "    \"\"\"\"\n",
    "    Stack third axis-wise. all \n",
    "    tifs must be same extent and in sorted order by date\n",
    "    \"\"\"\n",
    "    arrs = [ski.io.imread(path) for path in paths]\n",
    "    stacked = reshape_as_raster(np.dstack(arrs))\n",
    "    img = rio.open(paths[0])\n",
    "    meta=img.profile\n",
    "    meta.update(count=len(arrs)*arrs[0].shape[2])\n",
    "    with rio.open(stackname, 'w',  **meta) as dst:\n",
    "        dst.write(stacked)\n",
    "    print(\"Saved Time Series with \" + str(len(arrs)) + \" images and \" + str(arrs[0].shape[2]) + \" bands each\")\n",
    "\n",
    "stack_t_series(img_paths_with_meta, \"stacked.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_april = filter_date(img_paths, '04', 4,6)\n",
    "udms_april = filter_date(udm_paths, '04', 4,6)\n",
    "imgs_march = filter_date(img_paths, '03', 4,6)\n",
    "udms_march = filter_date(udm_paths, '03', 4,6)\n",
    "imgs_feb = filter_date(img_paths, '02', 4,6)\n",
    "udms_feb = filter_date(udm_paths, '02', 4,6)\n",
    "imgs_jan = filter_date(img_paths, '01', 4,6)\n",
    "udms_jan = filter_date(udm_paths, '01', 4,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_pattern = \"/home/rave/cloud-free-planet/notebooks/clipped-may/*SR*.tif\"\n",
    "img_paths = glob.glob(sr_pattern)\n",
    "udm_pattern = \"/home/rave/cloud-free-planet/notebooks/clipped-may/udms/*udm.tif\"\n",
    "udm_paths = glob.glob(udm_pattern)\n",
    "\n",
    "img_paths = sorted(img_paths)\n",
    "\n",
    "udm_paths = sorted(udm_paths)\n",
    "\n",
    "imgs_may = filter_date(img_paths, '05', 12,14)\n",
    "udms_may = filter_date(udm_paths, '05', 12,14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call with lyndon on cloud\n",
    "\n",
    "- date weighting (lyndon)\n",
    "- weighted mean 1-abs(cloud index-mean(cloud_index)) at each pixel. index could be ndvi, where low values are cloudy or https://www.researchgate.net/publication/327262968_CloudShadow_Detection_Framework_based_on_Spectral_Indices_for_MultiHyperspectral_Optical_Remote_Sensing_Imagery\n",
    "- shadows\n",
    "- shadow spatial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloud Mask Questions\n",
    "\n",
    "* How can we get rid of the confusion between bright urban surfaces and clouds? Currently we are using the two cloud indices. Either must be satisfied to be classified as a cloud\n",
    "\n",
    "    ci_one_arr = (b4_array*3)/(b1_array+b2_array+b3_array)\n",
    "    ci_two_arr = (b4_array+b1_array+b2_array+b3_array)/4\n",
    "\n",
    "* The mask is very sensitive to the coefficient used to make the second threshold. The second CI threshold is determined like so. Are there better ways to determine this threshold? Basically looking for alternative method suggestions.\n",
    "\n",
    "    ci_thresh_two = np.mean(ci_two_arr) + ci_coef_two*(np.max(ci_two_arr)-np.mean(ci_two_arr))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "from filter_callable import *\n",
    "plt.style.use('dark_background')\n",
    "test_path = imgs_may[12]\n",
    "test_udm_path = udms_may[12]\n",
    "plt.figure(figsize=(9,9))\n",
    "test = rio.open(test_path)\n",
    "b1_array, b2_array, b3_array, b4_array = test.read()\n",
    "band_list = [b1_array ,b2_array, b3_array, b4_array]\n",
    "stacked = np.dstack(band_list)\n",
    "plt.imshow(percentile_rescale(reorder_to_rgb(stacked)))\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "test_cloud = cloud_stats_zhen(test_path, ci_coef_two=1/8, ci_thresh_one=.5, med_kernel=5, object_size_thresh=100)\n",
    "plt.title(\"zhen et al. mask\")\n",
    "plt.imshow(test_cloud)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "arr = ski.io.imread(test_udm_path)\n",
    "plt.title(\"udm mask\")\n",
    "plt.imshow(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad Shadow Mask Questions\n",
    "* can we improve this with match filtering using the cloud masks as templates and the sun elevation, azimuth and view angle information? \n",
    "\n",
    "* How could we assume or estimate the cloud height without brightness temperature (similar to what Fmask does)? \n",
    "\n",
    "* How could we do a match filtering that doesn't depend on scene metadata if we can't assume cloud height?\n",
    "\n",
    "* Because match filtering wouldn't be able to account for shadows at the edge of the image, we'd probably want to run this on the whole Planet scene, focusing more on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filter_callable import *\n",
    "test = rio.open(imgs_may[0])\n",
    "b1_array, b2_array, b3_array, b4_array = test.read()\n",
    "band_list = [b1_array ,b2_array, b3_array, b4_array]\n",
    "stacked = np.dstack(band_list)\n",
    "\n",
    "shadow_array_initial = initial_shadow_filter(stacked, shadow_reflectance_thresh=3100)\n",
    "shadow_array = shadow_size_shape_filter(shadow_array_initial, \n",
    "                                        object_size_thresh=200, \n",
    "                                        eccentricity_thresh=.95, \n",
    "                                        peri_to_area_ratio=.3)\n",
    "print(np.count_nonzero(shadow_array_initial))\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(percentile_rescale(reorder_to_rgb(stacked)))\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(shadow_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "plt.hist(stacked[:,:,3].flatten(), bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below block plots all the images and masks for a month, needs to be functionalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20, 350))\n",
    "columns = 3\n",
    "rows = 78\n",
    "plot_indices = list(range(1,78))\n",
    "path_indices = list(range(1, 26))\n",
    "for i, even, odd, by_3 in zip(path_indices, even_no_3_only(plot_indices), odd_no_3_only(plot_indices), by_3_only(plot_indices)):\n",
    "    udm_masked = test_udm_mask(imgs_may[i], udms_may[i])\n",
    "    custom_masked = test_custom_mask(imgs_may[i])\n",
    "    udm_masked = normalize(udm_masked)\n",
    "    custom_masked = normalize(custom_masked)\n",
    "    udm_masked_rgb = reorder_to_brg(udm_masked)\n",
    "    custom_masked_rgb = reorder_to_brg(custom_masked)\n",
    "    fig.add_subplot(rows, columns, even)\n",
    "    plt.imshow(percentile_rescale(udm_masked_rgb, plow=.5, phigh=99.5))\n",
    "    plt.title(\"UDM\")\n",
    "    fig.add_subplot(rows, columns, odd)\n",
    "    plt.imshow(percentile_rescale(custom_masked_rgb, plow=.5, phigh=99.5))\n",
    "    plt.title(\"Custom Mask\")\n",
    "    fig.add_subplot(rows, columns, by_3)\n",
    "    img = ski.io.imread(imgs_may[i])\n",
    "    plt.imshow(img[:,:,0])\n",
    "    plt.title(\"Blue Band No Mask\")                     \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"all_may_images.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_median_composite(imgs, udms):\n",
    "    \"\"\"Take slist of image arrays and udm arrays\"\"\"\n",
    "    udm_mask_arrs = [test_udm_mask(img, udm).astype(float) for img,udm in zip(imgs, udms)]\n",
    "    custom_mask_arrs = [test_custom_mask(img).astype(float) for img in imgs_may]\n",
    "    for arr in udm_mask_arrs:\n",
    "        arr[arr==0] = np.nan\n",
    "    for arr in custom_mask_arrs:\n",
    "        arr[arr==0] = np.nan\n",
    "    udm_masked_med = np.nanmedian(udm_mask_arrs, axis=0)\n",
    "    custom_masked_med = np.nanmedian(custom_mask_arrs, axis=0)\n",
    "    return (udm_masked_med, custom_masked_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jan_composites = make_median_composite(imgs_jan, udms_jan)\n",
    "feb_composites = make_median_composite(imgs_feb, udms_feb)\n",
    "march_composites = make_median_composite(imgs_march, udms_march)\n",
    "april_composites = make_median_composite(imgs_april, udms_april)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_composites = make_median_composite(imgs_may, udms_may)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_may_april = imgs_may +imgs_april\n",
    "udms_may_april = udms_may + udms_april\n",
    "\n",
    "may_april_composites = make_median_composite(imgs_may_april, udms_may_april)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_may_jan = imgs_may +imgs_april + imgs_march +imgs_feb +imgs_jan\n",
    "udms_may_jan = udms_may + udms_april + imgs_march +imgs_feb +imgs_jan\n",
    "\n",
    "may_jan_composites = make_median_composite(imgs_may_jan, udms_may_jan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ski.io.imshow(\n",
    "    percentile_rescale(\n",
    "        reorder_to_brg(\n",
    "            normalize(\n",
    "                np.nan_to_num(may_jan_composites[0])\n",
    "            ))))\n",
    "plt.title(\"jan to may median composite (udm)\")\n",
    "plt.savefig('udm_composite_may_jan.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ski.io.imshow(\n",
    "    percentile_rescale(\n",
    "        reorder_to_brg(\n",
    "            normalize(\n",
    "                np.nan_to_num(custom_masked_med)\n",
    "            ))))\n",
    "plt.title(\"custom may composite\")\n",
    "plt.savefig('custom_composite_may.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is older code for saving out the masked images when I was using GRASS GIS to do the median compositing. Solved median compositing in numpy now above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_mask(image_path):\n",
    "    \"\"\"\n",
    "    Masks a custom cloud mask from filter_callable\n",
    "    \"\"\"\n",
    "\n",
    "    img = rio.open(image_path)\n",
    "    img_meta = img.profile\n",
    "    cloud_arr, shadow_arr = cloud_shadow_stats(image_path)\n",
    "    masked = np.where(cloud_arr,img.read(), 0)\n",
    "    # need to fix this shdow mask #masked = np.where(shadow_arr,masked, 0)\n",
    "    with rio.open(image_path[0:-12]+'custom_masked.tif', 'w', **img_meta) as dst:\n",
    "        dst.write(masked) # when mask is true yield img, otherwise yield nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(custom_mask, img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_udm_and_mask(img_path):\n",
    "    \n",
    "    def udm_mask(image_path, udm_path):\n",
    "        \"\"\"\n",
    "        Masks a planet image by it's udm\n",
    "        \"\"\"\n",
    "    \n",
    "        img = rio.open(image_path)\n",
    "        img_meta = img.profile\n",
    "        img_array = np.array([img.read(1), img.read(2), img.read(3), img.read(4)])\n",
    "        mask = rio.open(udm_path).read(1)[..., :] == 0 # 0 is the value in the udm that corresponds to good data\n",
    "        masked = np.where(mask,img_array, 0)\n",
    "        with rio.open(img_path[0:-12]+'masked.tif', 'w', **img_meta) as dst:\n",
    "            dst.write(masked) # when mask is true yield img, otherwise yield nan\n",
    "        \n",
    "    if os.path.isfile(img_path) and os.path.isfile(img_path[0:-12]+'_DN_udm_clip.tif'):\n",
    "        udm_mask(img_path, img_path[0:-12]+'_DN_udm_clip.tif')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "map(check_udm_and_mask, img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_pattern = \"/home/rave/cloud-free-planet/mosaic-tests/*custom*.tif\"\n",
    "masked_paths = glob.glob(masked_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "def save_single_bands(t):\n",
    "    \"\"\"\n",
    "    Takes a band index and a path. Saves the\n",
    "    specified band of each tif and names it by the band index. \n",
    "    \"\"\"\n",
    "    (band_index, path) = t\n",
    "    img = rio.open(path)\n",
    "    meta = img.profile\n",
    "    meta.update(count=1) # update since we are writing a single band\n",
    "    arr = img.read(band_index)\n",
    "    dst_path = os.path.join(os.path.dirname(path),\"Band_\"+str(band_index)+\"_\"+os.path.basename(path))\n",
    "    with rio.open(dst_path, 'w', **meta) as dst:\n",
    "        dst.write(arr, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 3, 4]:\n",
    "    list(map(save_single_bands, [(i, x) for x in masked_paths]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above functions take raw analytic_sr that has been clipped and the udm masks and masks the data, then saves each band seperately out. Median compositing is done in GRASS GIS, because couldn't figure out how to median composite partially overlapping arrays wtih rasterio and numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for creating Coarse Africa Grid in Decimal Degrees, WGS84 Datum\n",
    "\n",
    "Below is the coarse layout defined in geopyspark to merge model outputs. Each tile is .0512 degrees by .0512 degrees. need to make a shapely multi line string or polygon bject that can be used to save out tiles as geojsons (only if they intersect an aoi) so that we can use each tile geojson with porder\n",
    "\n",
    "coarse_layout = gps.LayoutDefinition(gps.Extent(-17.541, -34.845, 51.4766, 37.5518), gps.TileLayout(1348, 1414, 4096, 4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio import mask\n",
    "import rasterstats as rstats\n",
    "import skimage as ski\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "import json\n",
    "\n",
    "def layout_to_geojson(extent=(-17.541, -34.845, 51.459, 37.555), stepsize=.0025, output_name=\"./supercell_tile_grid.geojson\"):\n",
    "    \"\"\"\n",
    "    :param extent: (lonmin, latmin, lonmax, latmax) checked this by \n",
    "    looking at coarse layout in run_geopyspark\n",
    "    \n",
    "    :param stepsize: width and height of tile in degrees, checked \n",
    "    this by measuring extent of probability image tiles\n",
    "    \n",
    "    :returns: nothing, saves a geodataframe to a geojson file that encodes the supercell grid\n",
    "    \"\"\"\n",
    "    \n",
    "    (lonmin, latmin, lonmax, latmax) = extent\n",
    "    cols = (lonmax - lonmin)/stepsize\n",
    "    rows = (latmax - latmin)/stepsize\n",
    "    # Top left corner of grid, where we start to build the gdf\n",
    "    XleftOrigin = lonmin\n",
    "    XrightOrigin = lonmin + stepsize\n",
    "    YtopOrigin = latmax\n",
    "    YbottomOrigin = latmax - stepsize\n",
    "    polygons = []\n",
    "    \n",
    "    for i in range(int(cols)):\n",
    "        \n",
    "        Ytop = YtopOrigin\n",
    "        Ybottom =YbottomOrigin\n",
    "        for j in range(int(rows)):\n",
    "            polygons.append(Polygon([(XleftOrigin, Ytop), (XrightOrigin, Ytop), (XrightOrigin, Ybottom), (XleftOrigin, Ybottom)])) \n",
    "            Ytop = Ytop - stepsize\n",
    "            Ybottom = Ybottom - stepsize\n",
    "        XleftOrigin = XleftOrigin + stepsize\n",
    "        XrightOrigin = XrightOrigin + stepsize\n",
    "\n",
    "    grid = gpd.GeoDataFrame({'geometry':polygons})\n",
    "    grid.to_file(output_name, driver = \"GeoJSON\")\n",
    "    \n",
    "layout_to_geojson(extent = (-4.511, 4.46, 1.824, 11.54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi1_polygon = gpd.read_file(\"../cfg/aois/4.geojson\")['geometry'][0]\n",
    "grid_gdf = gpd.read_file(\"./supercell_tile_grid.geojson\")\n",
    "\n",
    "aoi1_grid_geometries = grid_gdf.intersection(aoi1_polygon)\n",
    "aoi1_grid_geometries= aoi1_grid_geometries[aoi1_grid_geometries.is_empty==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi1_grid_geometries[aoi1_grid_geometries.geom_type=='LineString'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi1_grid_geometries[aoi1_grid_geometries.geom_type=='Polygon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi1_grid_geometries.loc[3448740:3448744]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi1_grid_geometries.loc[3251750:3251755][aoi1_grid_geometries.geom_type=='Polygon'].to_file('mapper0_tile_subset.geojson', driver= \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_geoms=aoi1_grid_geometries.loc[3248740:3248742]\n",
    "\n",
    "gpd.GeoSeries([test_geoms]).to_file('test_tiles.geojson', driver= \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.GeoSeries([test_geoms]).to_file('test_tile.geojson', driver= \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ssh for idlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porder idlist --input \"/home/rave/cloud-free-planet/notebooks/test_aoi_ghana_larger.geojson\" --start \"2018-01-01\" --end \"2018-09-30\" --item \"PSScene4Band\" --asset \"analytic_sr\" --number 10000 --outfile \"/home/rave/cloud-free-planet/notebooks/test_aoi1_id.csv\" --cmin 0 --cmax .7 --overlap 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ssh command for ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porder order --name larger_ghana_aoi --idlist /home/rave/cloud-free-planet/notebooks/test_aoi1_id.txt --item PSScene4Band --asset analytic_sr --boundary /home/rave/cloud-free-planet/notebooks/test_aoi_ghana_larger.geojson --op clip email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porder multiproc --url https://api.planet.com/compute/ops/orders/v2/d277df43-b783-4b00-ad29-b5df5662af64 --local /home/rave/cloud-free-planet/notebooks/jan-september/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE\n",
    "p = Popen(\"porder\",stdout=PIPE, stderr=PIPE)\n",
    "stdout, stderr = p.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stderr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geo]",
   "language": "python",
   "name": "conda-env-geo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
