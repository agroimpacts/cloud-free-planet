{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing planet imagery for median mosaic\n",
    "\n",
    "1. mask clouds\n",
    "2. assign nodata for partial overlap scenes within bounds of supercell\n",
    "3. median for each band and composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio import mask\n",
    "import rasterstats as rstats\n",
    "import skimage as ski\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "os.chdir('../')\n",
    "from filter_callable import cloud_shadow_stats\n",
    "sr_pattern = \"/home/rave/cloud-free-planet/mosaic-tests/*SR*\"\n",
    "img_paths = glob.glob(sr_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_mask(image_path):\n",
    "    \"\"\"\n",
    "    Masks a custom cloud mask from filter_callable\n",
    "    \"\"\"\n",
    "\n",
    "    img = rio.open(image_path)\n",
    "    img_meta = img.profile\n",
    "    cloud_arr, shadow_arr = cloud_shadow_stats(image_path)\n",
    "    masked = np.where(cloud_arr,img.read(), 0)\n",
    "    # need to fix this shdow mask #masked = np.where(shadow_arr,masked, 0)\n",
    "    with rio.open(image_path[0:-12]+'custom_masked.tif', 'w', **img_meta) as dst:\n",
    "        dst.write(masked) # when mask is true yield img, otherwise yield nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(custom_mask, img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_udm_and_mask(img_path):\n",
    "    \n",
    "    def udm_mask(image_path, udm_path):\n",
    "        \"\"\"\n",
    "        Masks a planet image by it's udm\n",
    "        \"\"\"\n",
    "    \n",
    "        img = rio.open(image_path)\n",
    "        img_meta = img.profile\n",
    "        img_array = np.array([img.read(1), img.read(2), img.read(3), img.read(4)])\n",
    "        mask = rio.open(udm_path).read(1)[..., :] == 0 # 0 is the value in the udm that corresponds to good data\n",
    "        masked = np.where(mask,img_array, 0)\n",
    "        with rio.open(img_path[0:-12]+'masked.tif', 'w', **img_meta) as dst:\n",
    "            dst.write(masked) # when mask is true yield img, otherwise yield nan\n",
    "        \n",
    "    if os.path.isfile(img_path) and os.path.isfile(img_path[0:-12]+'_DN_udm_clip.tif'):\n",
    "        udm_mask(img_path, img_path[0:-12]+'_DN_udm_clip.tif')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "map(check_udm_and_mask, img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_pattern = \"/home/rave/cloud-free-planet/mosaic-tests/*custom*.tif\"\n",
    "masked_paths = glob.glob(masked_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "def save_single_bands(t):\n",
    "    \"\"\"\n",
    "    Takes a band index and a path. Saves the\n",
    "    specified band of each tif and names it by the band index. \n",
    "    \"\"\"\n",
    "    (band_index, path) = t\n",
    "    img = rio.open(path)\n",
    "    meta = img.profile\n",
    "    meta.update(count=1) # update since we are writing a single band\n",
    "    arr = img.read(band_index)\n",
    "    dst_path = os.path.join(os.path.dirname(path),\"Band_\"+str(band_index)+\"_\"+os.path.basename(path))\n",
    "    with rio.open(dst_path, 'w', **meta) as dst:\n",
    "        dst.write(arr, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 3, 4]:\n",
    "    list(map(save_single_bands, [(i, x) for x in masked_paths]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above functions take raw analytic_sr that has been clipped and the udm masks and masks the data, then saves each band seperately out. Median compositing is done in GRASS GIS, because couldn't figure out how to median composite partially overlapping arrays wtih rasterio and numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for creating Coarse Africa Grid in Decimal Degrees, WGS84 Datum\n",
    "\n",
    "Below is the coarse layout defined in geopyspark to merge model outputs. Each tile is .0512 degrees by .0512 degrees. need to make a shapely multi line string or polygon bject that can be used to save out tiles as geojsons (only if they intersect an aoi) so that we can use each tile geojson with porder\n",
    "\n",
    "coarse_layout = gps.LayoutDefinition(gps.Extent(-17.541, -34.845, 51.4766, 37.5518), gps.TileLayout(1348, 1414, 4096, 4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layout_to_geojson(extent=(-17.541, -34.845, 51.4766, 37.5518), stepsize=.0512, output_name=\"/dev/data/tile_grid.geojson\"):\n",
    "    \"\"\"\n",
    "    :param extent: (lonmin, latmin, lonmax, latmax) checked this by \n",
    "    looking at coarse layout in run_geopyspark\n",
    "    \n",
    "    :param stepsize: width and height of tile in degrees, checked \n",
    "    this by measuring extent of probability image tiles\n",
    "    \n",
    "    :returns: a geodataframe where each row is a tile polygon\n",
    "    \"\"\"\n",
    "    \n",
    "    (lonmin, latmin, lonmax, latmax) = extent\n",
    "    cols = (lonmax - lonmin)/.0512\n",
    "    rows = (latmax - latmin)/.0512\n",
    "    # Top left corner of grid, where we start to build the gdf\n",
    "    XleftOrigin = lonmin\n",
    "    XrightOrigin = lonmin + stepsize\n",
    "    YtopOrigin = latmax\n",
    "    YbottomOrigin = latmax - stepsize\n",
    "    polygons = []\n",
    "    \n",
    "    for i in range(int(cols)):\n",
    "        \n",
    "        Ytop = YtopOrigin\n",
    "        Ybottom =YbottomOrigin\n",
    "        for j in range(int(rows)):\n",
    "            polygons.append(Polygon([(XleftOrigin, Ytop), (XrightOrigin, Ytop), (XrightOrigin, Ybottom), (XleftOrigin, Ybottom)])) \n",
    "            Ytop = Ytop - stepsize\n",
    "            Ybottom = Ybottom - stepsize\n",
    "        XleftOrigin = XleftOrigin + stepsize\n",
    "        XrightOrigin = XrightOrigin + stepsize\n",
    "\n",
    "    grid = gpd.GeoDataFrame({'geometry':polygons})\n",
    "    grid.to_file(output_name, driver = \"GeoJSON\")\n",
    "    \n",
    "layout_to_geojson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi1_polygon = gpd.read_file(\"../cfg/aois/1.geojson\")['geometry'][0]\n",
    "grid_gdf = gpd.read_file(\"/dev/data/tile_grid.geojson\")\n",
    "\n",
    "aoi1_grid_geometries = grid_gdf.intersection(aoi1_polygon)\n",
    "aoi1_grid_geometries= aoi1_grid_geometries[aoi1_grid_geometries.is_empty==False]\n",
    "\n",
    "test_geom=aoi1_grid_geometries.iloc[6]\n",
    "\n",
    "gpd.GeoSeries([test_geom]).to_file('test_tile.geojson', driver= \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpd.GeoSeries([test_geom]).to_file('test_tile.geojson', driver= \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ssh for idlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "porder idlist --input \"/home/ubuntu/planet/cloud-free-planet/notebooks/test_tile.geojson\" --start \"2018-07-01\" --end \"2018-07-31\" --item \"PSScene4Band\" --asset \"analytic_sr\" --number 10000 --outfile \"/home/ubuntu/planet/cloud-free-planet/notebooks/test_aoi1_id.csv\" --cmin 0 --cmax 1 --overlap 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ssh command for ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "porder order --name test-aoi1-month07 --idlist ~/planet/cloud-free-planet/notebooks/test_aoi1_id.txt --item PSScene4Band --asset analytic_sr --boundary test_tile.geojson --aws ~/planet/cloud-free-planet/notebooks/aws.yaml --op aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE\n",
    "p = Popen(\"porder\",stdout=PIPE, stderr=PIPE)\n",
    "stdout, stderr = p.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stderr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geo]",
   "language": "python",
   "name": "conda-env-geo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
