{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing planet imagery for median mosaic\n",
    "\n",
    "1. mask clouds\n",
    "2. assign nodata for partial overlap scenes within bounds of supercell\n",
    "3. median for each band and composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio import mask\n",
    "import rasterstats as rstats\n",
    "import skimage as ski\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "os.chdir('../')\n",
    "from filter_callable import cloud_shadow_stats\n",
    "sr_pattern = \"/home/rave/cloud-free-planet/notebooks/small_supercell_and_full_scenes_May-September/clipped/*.tif\"\n",
    "img_paths = glob.glob(sr_pattern)\n",
    "udm_pattern = \"/home/rave/cloud-free-planet/notebooks/small_supercell_and_full_scenes_May-September/clipped/udms/*.tif\"\n",
    "udm_paths = glob.glob(udm_pattern)\n",
    "\n",
    "img_paths = sorted(img_paths)\n",
    "\n",
    "udm_paths = sorted(udm_paths)\n",
    "\n",
    "def filter_date(lst, month_int, month_digit1, month_digit2):\n",
    "    \"\"\"Takes a list of udms or images and returns filtered by month lists\"\"\"\n",
    "    return [i for i in lst if os.path.basename(i)[month_digit1:month_digit2] == month_int]\n",
    "imgs_may = filter_date(img_paths, '05', 12, 14)\n",
    "udms_may = filter_date(udm_paths, '05', 12, 14)\n",
    "\n",
    "def test_udm_mask(image_path, udm_path):\n",
    "    \"\"\"\n",
    "    Masks a planet image by it's udm\n",
    "    \"\"\"\n",
    "\n",
    "    img = rio.open(image_path)\n",
    "    img_meta = img.profile\n",
    "    img_array = np.array([img.read(1), img.read(2), img.read(3), img.read(4)])\n",
    "    mask = rio.open(udm_path).read(1)[..., :] == 0 # 0 is the value in the udm that corresponds to good data\n",
    "    masked = np.where(mask,img_array, 0)\n",
    "    return np.swapaxes(np.swapaxes(masked, 0, 2),0, 1)\n",
    "\n",
    "\n",
    "def test_custom_mask(image_path):\n",
    "    \"\"\"\n",
    "    Masks a custom cloud mask from filter_callable\n",
    "    \"\"\"\n",
    "\n",
    "    img = rio.open(image_path)\n",
    "    img_meta = img.profile\n",
    "    cloud_arr, shadow_arr = cloud_shadow_stats(image_path)\n",
    "    cloud_arr = np.logical_not(cloud_arr.astype(bool))\n",
    "    shadow_arr = np.logical_not(shadow_arr.astype(bool))\n",
    "    masked = np.where(cloud_arr,img.read(), False)\n",
    "    masked = np.where(shadow_arr,masked, False)\n",
    "    return np.swapaxes(np.swapaxes(masked, 0, 2),0, 1)\n",
    "\n",
    "from skimage import exposure\n",
    "\n",
    "def percentile_rescale(arr, plow=1, phigh=99):\n",
    "    '''\n",
    "    Rescales and applies other exposure functions to improve image vis. \n",
    "    http://scikit-image.org/docs/dev/api/skimage.exposure.html#skimage.exposure.rescale_intensity\n",
    "    '''\n",
    "    rescaled_arr = np.zeros_like(arr)\n",
    "    for i in range(0,arr.shape[-1]):\n",
    "        val_range = (np.percentile(arr[:,:,i], plow), np.percentile(arr[:,:,i], phigh))\n",
    "        rescaled_channel = exposure.rescale_intensity(arr[:,:,i], val_range)\n",
    "        rescaled_arr[:,:,i] = rescaled_channel\n",
    "#     rescaled_arr= exposure.adjust_gamma(rescaled_arr, gamma=1) #adjust from 1 either way\n",
    "#     rescaled_arr= exposure.adjust_sigmoid(rescaled_arr, cutoff=.50) #adjust from .5 either way \n",
    "    return rescaled_arr\n",
    "def normalize(arr):\n",
    "    ''' Function to normalize an input array to 0-1 '''\n",
    "    arr_max = arr.max()\n",
    "    return arr / arr_max\n",
    "\n",
    "def reorder_to_brg(image):\n",
    "    '''reorders wv2 bands ordered like RGBNRGN for off/onseason\n",
    "    to blue, red, green for imshow\n",
    "    '''\n",
    "    blue = normalize(image[:,:,2])\n",
    "    green = normalize(image[:,:,1])\n",
    "    red = normalize(image[:,:,0])\n",
    "    nir = normalize(image[:,:,3])\n",
    "    return np.stack([blue, red, green], axis=-1)\n",
    "\n",
    "def is_even(x):\n",
    "    if x%2 == 1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "def is_div_by(x, y):\n",
    "    if x%y == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def even_only(iter):\n",
    "    return [x for x in iter if is_even(x)]\n",
    "def odds_only(iter):\n",
    "    return [x for x in iter if not is_even(x)]\n",
    "def by_3_only(iter):\n",
    "    return [x for x in iter if is_div_by(x, 3)]\n",
    "def by_3_no_odd_only(iter):\n",
    "    return [x for x in iter if is_div_by(x, 3) and is_even(x)]\n",
    "def even_no_3_only(iter):\n",
    "    return [x for x in iter if not is_div_by(x, 3) and is_even(x)]\n",
    "def odd_no_3_only(iter):\n",
    "    return [x for x in iter if not is_div_by(x, 3) and not is_even(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below block plots all the images and masks for a month, needs to be functionalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20, 350))\n",
    "columns = 3\n",
    "rows = 78\n",
    "plot_indices = list(range(1,78))\n",
    "path_indices = list(range(1, 26))\n",
    "for i, even, odd, by_3 in zip(path_indices, even_no_3_only(plot_indices), odd_no_3_only(plot_indices), by_3_only(plot_indices)):\n",
    "    udm_masked = test_udm_mask(imgs_may[i], udms_may[i])\n",
    "    custom_masked = test_custom_mask(imgs_may[i])\n",
    "    udm_masked = normalize(udm_masked)\n",
    "    custom_masked = normalize(custom_masked)\n",
    "    udm_masked_rgb = reorder_to_brg(udm_masked)\n",
    "    custom_masked_rgb = reorder_to_brg(custom_masked)\n",
    "    fig.add_subplot(rows, columns, even)\n",
    "    plt.imshow(percentile_rescale(udm_masked_rgb, plow=.5, phigh=99.5))\n",
    "    plt.title(\"UDM\")\n",
    "    fig.add_subplot(rows, columns, odd)\n",
    "    plt.imshow(percentile_rescale(custom_masked_rgb, plow=.5, phigh=99.5))\n",
    "    plt.title(\"Custom Mask\")\n",
    "    fig.add_subplot(rows, columns, by_3)\n",
    "    img = ski.io.imread(imgs_may[i])\n",
    "    plt.imshow(img[:,:,0])\n",
    "    plt.title(\"Blue Band No Mask\")                     \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"all_may_images.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udm_mask_arrs = [test_udm_mask(img, udm).astype(float) for img,udm in zip(imgs_may, udms_may)]\n",
    "custom_mask_arrs = [test_custom_mask(img).astype(float) for img in imgs_may]\n",
    "for arr in udm_mask_arrs:\n",
    "    arr[arr==0] = np.nan\n",
    "for arr in custom_mask_arrs:\n",
    "    arr[arr==0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udm_masked_med = np.nanmedian(udm_mask_arrs, axis=0)\n",
    "custom_masked_med = np.nanmedian(custom_mask_arrs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ski.io.imshow(\n",
    "    percentile_rescale(\n",
    "        reorder_to_brg(\n",
    "            normalize(\n",
    "                np.nan_to_num(udm_masked_med)\n",
    "            ))))\n",
    "plt.title(\"udm may composite\")\n",
    "plt.savefig('udm_composite_may.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ski.io.imshow(\n",
    "    percentile_rescale(\n",
    "        reorder_to_brg(\n",
    "            normalize(\n",
    "                np.nan_to_num(custom_masked_med)\n",
    "            ))))\n",
    "plt.title(\"custom may composite\")\n",
    "plt.savefig('custom_composite_may.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is older code for saving out the masked images when I was using GRASS GIS to do the median compositing. Solved median compositing in numpy now above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_mask(image_path):\n",
    "    \"\"\"\n",
    "    Masks a custom cloud mask from filter_callable\n",
    "    \"\"\"\n",
    "\n",
    "    img = rio.open(image_path)\n",
    "    img_meta = img.profile\n",
    "    cloud_arr, shadow_arr = cloud_shadow_stats(image_path)\n",
    "    masked = np.where(cloud_arr,img.read(), 0)\n",
    "    # need to fix this shdow mask #masked = np.where(shadow_arr,masked, 0)\n",
    "    with rio.open(image_path[0:-12]+'custom_masked.tif', 'w', **img_meta) as dst:\n",
    "        dst.write(masked) # when mask is true yield img, otherwise yield nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(custom_mask, img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_udm_and_mask(img_path):\n",
    "    \n",
    "    def udm_mask(image_path, udm_path):\n",
    "        \"\"\"\n",
    "        Masks a planet image by it's udm\n",
    "        \"\"\"\n",
    "    \n",
    "        img = rio.open(image_path)\n",
    "        img_meta = img.profile\n",
    "        img_array = np.array([img.read(1), img.read(2), img.read(3), img.read(4)])\n",
    "        mask = rio.open(udm_path).read(1)[..., :] == 0 # 0 is the value in the udm that corresponds to good data\n",
    "        masked = np.where(mask,img_array, 0)\n",
    "        with rio.open(img_path[0:-12]+'masked.tif', 'w', **img_meta) as dst:\n",
    "            dst.write(masked) # when mask is true yield img, otherwise yield nan\n",
    "        \n",
    "    if os.path.isfile(img_path) and os.path.isfile(img_path[0:-12]+'_DN_udm_clip.tif'):\n",
    "        udm_mask(img_path, img_path[0:-12]+'_DN_udm_clip.tif')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "map(check_udm_and_mask, img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_pattern = \"/home/rave/cloud-free-planet/mosaic-tests/*custom*.tif\"\n",
    "masked_paths = glob.glob(masked_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "def save_single_bands(t):\n",
    "    \"\"\"\n",
    "    Takes a band index and a path. Saves the\n",
    "    specified band of each tif and names it by the band index. \n",
    "    \"\"\"\n",
    "    (band_index, path) = t\n",
    "    img = rio.open(path)\n",
    "    meta = img.profile\n",
    "    meta.update(count=1) # update since we are writing a single band\n",
    "    arr = img.read(band_index)\n",
    "    dst_path = os.path.join(os.path.dirname(path),\"Band_\"+str(band_index)+\"_\"+os.path.basename(path))\n",
    "    with rio.open(dst_path, 'w', **meta) as dst:\n",
    "        dst.write(arr, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 3, 4]:\n",
    "    list(map(save_single_bands, [(i, x) for x in masked_paths]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above functions take raw analytic_sr that has been clipped and the udm masks and masks the data, then saves each band seperately out. Median compositing is done in GRASS GIS, because couldn't figure out how to median composite partially overlapping arrays wtih rasterio and numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for creating Coarse Africa Grid in Decimal Degrees, WGS84 Datum\n",
    "\n",
    "Below is the coarse layout defined in geopyspark to merge model outputs. Each tile is .0512 degrees by .0512 degrees. need to make a shapely multi line string or polygon bject that can be used to save out tiles as geojsons (only if they intersect an aoi) so that we can use each tile geojson with porder\n",
    "\n",
    "coarse_layout = gps.LayoutDefinition(gps.Extent(-17.541, -34.845, 51.4766, 37.5518), gps.TileLayout(1348, 1414, 4096, 4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layout_to_geojson(extent=(-17.541, -34.845, 51.4766, 37.5518), stepsize=.0512, output_name=\"/dev/data/tile_grid.geojson\"):\n",
    "    \"\"\"\n",
    "    :param extent: (lonmin, latmin, lonmax, latmax) checked this by \n",
    "    looking at coarse layout in run_geopyspark\n",
    "    \n",
    "    :param stepsize: width and height of tile in degrees, checked \n",
    "    this by measuring extent of probability image tiles\n",
    "    \n",
    "    :returns: a geodataframe where each row is a tile polygon\n",
    "    \"\"\"\n",
    "    \n",
    "    (lonmin, latmin, lonmax, latmax) = extent\n",
    "    cols = (lonmax - lonmin)/.0512\n",
    "    rows = (latmax - latmin)/.0512\n",
    "    # Top left corner of grid, where we start to build the gdf\n",
    "    XleftOrigin = lonmin\n",
    "    XrightOrigin = lonmin + stepsize\n",
    "    YtopOrigin = latmax\n",
    "    YbottomOrigin = latmax - stepsize\n",
    "    polygons = []\n",
    "    \n",
    "    for i in range(int(cols)):\n",
    "        \n",
    "        Ytop = YtopOrigin\n",
    "        Ybottom =YbottomOrigin\n",
    "        for j in range(int(rows)):\n",
    "            polygons.append(Polygon([(XleftOrigin, Ytop), (XrightOrigin, Ytop), (XrightOrigin, Ybottom), (XleftOrigin, Ybottom)])) \n",
    "            Ytop = Ytop - stepsize\n",
    "            Ybottom = Ybottom - stepsize\n",
    "        XleftOrigin = XleftOrigin + stepsize\n",
    "        XrightOrigin = XrightOrigin + stepsize\n",
    "\n",
    "    grid = gpd.GeoDataFrame({'geometry':polygons})\n",
    "    grid.to_file(output_name, driver = \"GeoJSON\")\n",
    "    \n",
    "layout_to_geojson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi1_polygon = gpd.read_file(\"../cfg/aois/1.geojson\")['geometry'][0]\n",
    "grid_gdf = gpd.read_file(\"/dev/data/tile_grid.geojson\")\n",
    "\n",
    "aoi1_grid_geometries = grid_gdf.intersection(aoi1_polygon)\n",
    "aoi1_grid_geometries= aoi1_grid_geometries[aoi1_grid_geometries.is_empty==False]\n",
    "\n",
    "test_geom=aoi1_grid_geometries.iloc[6]\n",
    "\n",
    "gpd.GeoSeries([test_geom]).to_file('test_tile.geojson', driver= \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpd.GeoSeries([test_geom]).to_file('test_tile.geojson', driver= \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ssh for idlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "porder idlist --input \"/home/ubuntu/planet/cloud-free-planet/notebooks/test_tile.geojson\" --start \"2018-07-01\" --end \"2018-07-31\" --item \"PSScene4Band\" --asset \"analytic_sr\" --number 10000 --outfile \"/home/ubuntu/planet/cloud-free-planet/notebooks/test_aoi1_id.csv\" --cmin 0 --cmax 1 --overlap 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ssh command for ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "porder order --name test-aoi1-month07 --idlist ~/planet/cloud-free-planet/notebooks/test_aoi1_id.txt --item PSScene4Band --asset analytic_sr --boundary test_tile.geojson --aws ~/planet/cloud-free-planet/notebooks/aws.yaml --op aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE\n",
    "p = Popen(\"porder\",stdout=PIPE, stderr=PIPE)\n",
    "stdout, stderr = p.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stderr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geo]",
   "language": "python",
   "name": "conda-env-geo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
